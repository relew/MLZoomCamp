{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dab0d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dfe7c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91a92fc",
   "metadata": {},
   "source": [
    "# Splittting train dataset into train-val datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6edae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1594 files [01:01, 26.02 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "\n",
    "splitfolders.ratio(\"./dino-dragon/train\", output=\"./dino-dragon\",\n",
    "    seed=1337, ratio=(.8, .2), group_prefix=None, move=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b14949",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25940da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1274 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n",
      "Found 394 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dataset = train_gen.flow_from_directory('./dino-dragon/train',\n",
    "                              class_mode='binary',\n",
    "                              target_size=(150,150),\n",
    "                              batch_size=20,\n",
    "                              shuffle=True)\n",
    "\n",
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_dataset = val_gen.flow_from_directory('./dino-dragon/val',\n",
    "                              class_mode='binary',\n",
    "                              target_size=(150,150),\n",
    "                              batch_size=20,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_dataset = test_gen.flow_from_directory('./dino-dragon/test',\n",
    "                              class_mode='binary',\n",
    "                              target_size=(150,150),\n",
    "                              batch_size=20,\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c6168ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    #load input datasets\n",
    "    inputs = keras.Input(shape=(150,150,3))\n",
    "\n",
    "    #add convolutional layer\n",
    "    convolutional_layer = keras.layers.Conv2D(filters = 32,\n",
    "                                              kernel_size = (3,3),\n",
    "                                              activation='relu')(inputs)\n",
    "\n",
    "    #add pooling layer\n",
    "    pooling = keras.layers.MaxPool2D(pool_size=(2, 2))(convolutional_layer)\n",
    "    #convert the results to a vector dataset\n",
    "    vectors = keras.layers.Flatten()(pooling)\n",
    "    #add a dense layer with 64 neurons\n",
    "    dense = keras.layers.Dense(units = 64, activation = 'relu')(vectors)\n",
    "    #create output dataset containing 1 neurons\n",
    "    outputs = keras.layers.Dense(units = 1, activation = 'sigmoid')(dense)\n",
    "    \n",
    "    #create model\n",
    "    model = keras.Model(inputs,outputs)\n",
    "    #create optimizer\n",
    "    optimizer = keras.optimizers.SGD(lr=0.002, momentum=0.8)\n",
    "    #use BinaryCrossentripy for loss calculation\n",
    "    loss = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    model.compile(optimizer = optimizer,\n",
    "             loss = loss,\n",
    "             metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd988972",
   "metadata": {},
   "source": [
    "## Q1: BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab513340",
   "metadata": {},
   "source": [
    "## Q2: Total params: 11,215,873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52a6ff8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 175232)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                11214912  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c0ab6",
   "metadata": {},
   "source": [
    "# Generate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6005ba6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "64/64 [==============================] - 26s 404ms/step - loss: 0.7129 - accuracy: 0.5572 - val_loss: 0.6513 - val_accuracy: 0.5188\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 23s 361ms/step - loss: 0.6263 - accuracy: 0.6430 - val_loss: 0.5452 - val_accuracy: 0.7906\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.5203 - accuracy: 0.7593 - val_loss: 0.4525 - val_accuracy: 0.8344\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 23s 367ms/step - loss: 0.4112 - accuracy: 0.8276 - val_loss: 0.4217 - val_accuracy: 0.8375\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 23s 357ms/step - loss: 0.3736 - accuracy: 0.8502 - val_loss: 0.3665 - val_accuracy: 0.8500\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.3360 - accuracy: 0.8716 - val_loss: 0.3454 - val_accuracy: 0.8656\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 26s 408ms/step - loss: 0.3302 - accuracy: 0.8586 - val_loss: 0.3229 - val_accuracy: 0.8781\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 25s 393ms/step - loss: 0.2878 - accuracy: 0.9019 - val_loss: 0.3085 - val_accuracy: 0.8781\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 25s 395ms/step - loss: 0.2552 - accuracy: 0.9102 - val_loss: 0.2996 - val_accuracy: 0.8844\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 28s 431ms/step - loss: 0.2349 - accuracy: 0.9200 - val_loss: 0.3243 - val_accuracy: 0.8594\n"
     ]
    }
   ],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "                    'model_dino_{epoch:02d}_{val_accuracy:.3f}.h5',\n",
    "                     save_best_only= True,\n",
    "                     monitor = 'val_accuracy',\n",
    "                     mode = 'max')\n",
    "\n",
    "model = make_model()\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=10 , \n",
    "                    validation_data= val_dataset,\n",
    "                    callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9815d08",
   "metadata": {},
   "source": [
    "## Q3: median of training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1142746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8102040827274323"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "statistics.mean(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8869c37",
   "metadata": {},
   "source": [
    "## Q4: SD of training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ea220fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14955097056199543"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "statistics.stdev(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490c4d6b",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0739a1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1274 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n",
      "Found 394 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255,\n",
    "                               rotation_range=40,\n",
    "                               width_shift_range=0.2,\n",
    "                               height_shift_range=0.2,\n",
    "                               shear_range=0.2,\n",
    "                               zoom_range=0.2,\n",
    "                               horizontal_flip=True,\n",
    "                               fill_mode='nearest')\n",
    "\n",
    "train_dataset = train_gen.flow_from_directory('./dino-dragon/train',\n",
    "                              class_mode='binary',\n",
    "                              target_size=(150,150),\n",
    "                              batch_size=20,\n",
    "                              shuffle=True)\n",
    "\n",
    "val_gen = ImageDataGenerator(rescale=1./255,\n",
    "                               rotation_range=40,\n",
    "                               width_shift_range=0.2,\n",
    "                               height_shift_range=0.2,\n",
    "                               shear_range=0.2,\n",
    "                               zoom_range=0.2,\n",
    "                               horizontal_flip=True,\n",
    "                               fill_mode='nearest')\n",
    "\n",
    "val_dataset = val_gen.flow_from_directory('./dino-dragon/val',\n",
    "                              class_mode='binary',\n",
    "                              target_size=(150,150),\n",
    "                              batch_size=20,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255,\n",
    "                               rotation_range=40,\n",
    "                               width_shift_range=0.2,\n",
    "                               height_shift_range=0.2,\n",
    "                               shear_range=0.2,\n",
    "                               zoom_range=0.2,\n",
    "                               horizontal_flip=True,\n",
    "                               fill_mode='nearest')\n",
    "\n",
    "test_dataset = test_gen.flow_from_directory('./dino-dragon/test',\n",
    "                              class_mode='binary',\n",
    "                              target_size=(150,150),\n",
    "                              batch_size=20,\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "714bd1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "64/64 [==============================] - 35s 544ms/step - loss: 0.4846 - accuracy: 0.7630 - val_loss: 0.4618 - val_accuracy: 0.7875\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 35s 542ms/step - loss: 0.4747 - accuracy: 0.7669 - val_loss: 0.4248 - val_accuracy: 0.8438\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 36s 568ms/step - loss: 0.4521 - accuracy: 0.7936 - val_loss: 0.5468 - val_accuracy: 0.7437\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 34s 540ms/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4366 - val_accuracy: 0.7969\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 35s 543ms/step - loss: 0.4435 - accuracy: 0.7881 - val_loss: 0.3970 - val_accuracy: 0.8281\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 34s 528ms/step - loss: 0.4312 - accuracy: 0.8006 - val_loss: 0.4267 - val_accuracy: 0.7969\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 34s 539ms/step - loss: 0.4160 - accuracy: 0.8069 - val_loss: 0.3852 - val_accuracy: 0.8406\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 34s 525ms/step - loss: 0.4022 - accuracy: 0.8030 - val_loss: 0.3557 - val_accuracy: 0.8375\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 35s 542ms/step - loss: 0.3859 - accuracy: 0.8289 - val_loss: 0.3208 - val_accuracy: 0.8875\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 34s 539ms/step - loss: 0.3989 - accuracy: 0.8305 - val_loss: 0.4609 - val_accuracy: 0.7906\n"
     ]
    }
   ],
   "source": [
    "loaded_model = keras.models.load_model('model_dino_07_0.878.h5')\n",
    "new_history = loaded_model.fit(train_dataset,\n",
    "                               validation_data=val_dataset,\n",
    "                               epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293f7d4a",
   "metadata": {},
   "source": [
    "# Q5: mean of test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f55bce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.421614009141922"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(new_history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4be9d72",
   "metadata": {},
   "source": [
    "# Q6: avg of test accuracy for the last 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1eca8cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8306249856948853"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(new_history.history['val_accuracy'][5:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
